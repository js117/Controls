The Kalman Filter

This document derives the Kalman filter and documents the supporting software. 

====================
=== Introduction ===
====================

The Kalman filter is a minimum mean square estimator of a linear Gauss-Markov model
of the form:

x(t+1) = A*x(t) + w(t)
y(t) = C*x(t) + v(t)

We seek to make optimal estimates of the next state, given the system dynamics, noise model,
and prior measurements. We have both "process noise" w(t) as well as "measurement noise" v(t).

The following statistical assumptions apply: the model is a "Gaussian Process", meaning
that every quantity is a random variable with a Gaussian distribution, and together they
have a joint distribution. As well, we have: 

w(t) - IID with E(w(t)) = 0, Var(w(t)) = W
v(t) - IID with E(v(t)) = 0, Var(v(t)) = V
x(0) - E(x(0)) = mean(x(0)), Var(x(0)) = S(0) //where Var(x)==E((x-mean(x))*(x-mean(x))')

And the Markov property:

x(t)|(x(0),x(1),...,x(t-1)) = x(t)|x(t-1), i.e. only last state info is relevant

======================================
=== Minimum Mean Square Estimation ===
======================================

Given a random variables x and y (random vectors of length n and m respectively), we want to 
estimate x given y. In the Kalman filter, this will relate to estimating our next state
given all of our previous measurements Y(t) = (y(1), y(2), ..., y(t)). 

But first the general case of x and y; we seek a function x_est(y) such that we minimized
an error metric; a common metric is the mean-square error:

minimize E(norm(x_est(y) - x)^2),
 
i.e. minimize the expectation of the norm squared of the difference between the estimate and 
the actual. The general solution to this is:

x_est(y) = E(x|y)

I.e. the mean value of the conditional probability x given y. This quantity
is called the "minimum mean square estimator". 

Now we seek to find an expression for this quantity when x and y are jointly Gaussian, as is the
case for our "Gaussian Process" to which we wish to apply the "Kalman filter" to get an optimal
state estimate. 

If x and y, as above, are jointly Gaussian, then they have a normal distribution (vector definition
available at http://en.wikipedia.org/wiki/Multivariate_normal_distribution#Density_function) with
mean and variance given by:

(x, y)' ~ N( (mean(x), mean(y))', [Sx, Sxy; Sxy', Sy] ) //p(x,y), the joint

Where the variance is a 2x2 block matrix which is symmetric positive definite (as with all  
nondegenerate variance/covariance matrices). 

Now we must find the distribution p(x|y), the conditional. Using the joint probability above,
we write:

p(x|y) = p(x,y)/p(y) --> p(v|y) ~ exp(-1/2*(v - w)'*D.inv*(v - w)) //dummy variable v for notation

From this, we see that the distribution p(x|y) has a mean and variance:

w = mean(x) + Sxy*Sy.inv*(y - mean(y))

D = Sx - Sxy*Sy.inv*Sxy' //this is the Schur complement of Sy for the joint 2x2 block

And since x_est(y) = E(x|y), x_est(y) = w. We call this definition the "standard formula".

Some more algebra yields that the MMSE estimation error covariance is:

E((x_est(y) - x)*(x_est(y) - x)') = D

Which is the same as the covariance of the conditional distribution. Thus the MMSE estimation error
covariance is the same as the conditional distribution covariance.

================================
=== Linear Measurement Model ===
================================

A quick derivation of the joint probability of a linear measurement model will help in deriving
the Kalman Filter. Given a linear model with random vectors x in R(n), y in R(m), linear
transformation A in R(m x n), and sensor noise vector v in R(m), the linear measurement
model is:

y = A*x + v

y represents the actual measurements, x is the true quantity we want to estimate, and transform
A characterizes the sensors (perhaps doing things like converting units and/or forming a dynamics
model). We assume both x and v are normally distributed, with x ~ N(mean(x), Sx), v ~ N(mean(v), Sv).
They are almost independent.

We seek the joint distribution of [x, y]'. The expected values are simple; mean(x) is just the mean of x.
Since expectation is a linear operator, mean(y) = A*mean(x) + mean(v).

Now for covariance, we note that [x,y]' = [I, 0; A, I]*[x, v]', i.e. [x, y]' = M*[x, v]'. We know what the
distribution of [x, v]' looks like: just like the general experssion for joint Gaussians, except we have
Sxv = Svx' = 0, because x and v are independent. I.e.,

(x, v)' ~ N( (mean(x), mean(v))', [Sx, 0; 0, Sv] ) //the joint of p(x,y)

For a Gaussian distrbution w ~ N(mean(w), Sw), an affine transformation z = A*w + b is also Gaussian
with covariance Sz = A*Sz*A' (which is fairly easy to prove from the definition). 

Letting z = [x, y]', w = [x, v]', and noting that z = M*w as defined above, the covariance of [x,y]' is:

M*Sw*M' = [I, 0; A, I]*[Sx, 0; 0, Sv]*[I, 0; A, I]'

thus z = [x, y]' has distribution ~ N( (mean(x),A*mean(x)+mean(v))', [Sx, Sx*A'; A*Sx, A*Sx*A'+Sv] )

==================================
=== Deriving the Kalman Filter ===
==================================

To quickly recap our model, we have:

x(t+1) = A*x(t) + w(t)
y(t) = C*x(t) + v(t)

Where x(t) is a vector in R(n), y(t) is in R(p). Some additional notation, which we'll 
use both in the explanation and the software is required. Let:

var(t|s) == var(t)|Y(t-1) == var(t)|(y(1), y(2), ..., y(s)), where big Y is stacked column vectors, size s*p
//where 'var' can be our state vector estimate x_hat, or our covariance error matrix S

x_hat_previous <==> x_hat(t|t-1) (e.g. == E(x(t)|Y(t-1)), the expectation of the conditional)
x_hat_measured <==> x_hat(t|t)
x_hat_updated <==> x_hat(t+1|t)

And similar for the estimation error covariance matrices, i.e.

S_previous <==> S(t|t-1) == E((x(t) - x_hat(t|t-1))*(x(t) - x_hat(t|t-1))')
S_measured <==> S(t|t)
S_updated <==> S(t+1|t)

Theory: our process is Gaussian, so the current state x(t) and the sequence of measurements Y(t) are
jointly Gaussian. Thus as in the above section, the estimate based on these measurements is:

x_hat(t|t) = E(x(t)|Y(t)) = mean(x(t)) + S_xtYt*S_Yt.inv*(Yt - mean(Yt))

Where the above covariance matrices are significantly larger because they relate x(t) to Y(t), i.e. the
entire sequence of measurements. In fact, S_Yt is of size p*t x p*t, i.e. it grows in time t! Few 
algorithms can claim to quadratically in "space-time" (more so when you figure in the inverse).

One might now recall that our system's Markov property should come to the rescue: we don't need to full
measurement history, only the last one. This is what the Kalman filter does:

==> The Kalman filter is a clever way of computing our measured state and updated prediction recursively. 
I.e. we will not have to deal with the ever-expanding covariance matrices above. 

Part 1 - Measurement Update
---------------------------

We first seek to find x_hat(t|t) and S(t|t) in terms of x_hat(t|t-1) and S(t|t-1). 
I.e. measured predictions in terms of previous predictions. As a side note, in case it is not yet
obvious, every output quantity is a "prediction" because we have noise in our model. We never know
exactly what "x" is, hence we predict/estimate using the Kalman filter framework. 

Take the measurement equation of the model:

y(t) = C*x(t) + v(t)

Now condition on the measurements Y(t-1):

y(t)|Y(t-1) = C*x(t)|Y(t-1) + v(t) //recall that sensor noise v(t) is independent of x,y

This is simply a linear measurement model, albeit with more complicated looking expressions. No
matter, we know from the previous section that our variables have a normal distribution:

[x(t)|Y(t-1), y(t)|Y(t-1)]' ~ 

N( [x_hat(t|t-1), C*x_hat(t|t-1)]', [S(t|t-1), S(t|t-1)*C'; C*S(t|t-1), C*S(t|t-1)*C'+V] )

Where we recall the definition x_hat(t|t-1) == E(x(t)|Y(t-1)), and that mean(v) = 0. Of course
it's now simple to see how we change things if mean(v) != 0 (the above mean expression for y changes).
And for clarity we recall that the variable x(t)|Y(t-1) is normally distributed:

x(t)|Y(t-1) ~ N( mean(x(t)|Y(t-1)), S(t|t-1)) = N( x_hat(t|t-1), S(t|t-1)), 

with S(t|t-1) = E((x(t) - x_hat(t|t-1))*(x(t) - x_hat(t|t-1))').

Now to get at expressions for x_hat(t|t) and S(t|t) in terms of the above. Here we make note of the
following:

x(t)|Y(t) = ((x(t)|Y(t-1))|(y(t)|Y(t-1)))

Which makes sense, because being given y(t) in additional to Y(t-1) is equivalent to being given Y(t).

So using the normal distribution of (x(t)|Y(t-1), y(t)|Y(t-1)) above, we get the mean and variance of 
x(t)|Y(t) using the standard formula, i.e. we know E(x|y) from p(x|y) which is proportional to p(x,y) 
(i.e. p(x(t)|Y(t-1), y(t)|Y(t-1)) as above) and also 1/p(y). 

For clarity, the standard formula is repeated below:

w = mean(x) + Sxy*Sy.inv*(y - mean(y)) == E(x|y) == x_hat(t|t) for (x,y) = (x(t)|Y(t-1), y(t)|Y(t-1))
D = Sx - Sxy*Sy.inv*Sxy' == S(x|y) == S(t|t) 

Substituting in the expressions from the joint of (x(t)|Y(t-1), y(t)|Y(t-1)) with respect to the
standard formula, we get the "measurement update":

--------------------------------------------------------------------------------------
x_hat(t|t) = x_hat(t|t-1) + S(t|t-1)*C'*(C*S(t|t-1)*C'+V).inv*(y(t) - C*x_hat(t|t-1))

S(t|t) = S(t|t-1) - S(t|t-1)*C'*(C*S(t|t-1)*C'+V).inv*C*S(t|t-1)
--------------------------------------------------------------------------------------

We note that measured values are a function of previously predicted values. 

Part 2 - Time Update
--------------------

We now turn our attention to the next state equation, x(t+1) = A*x(t) + w(t), and apply a similar
methodology: our objective is to find expressions for x_hat(t+1|t) and S(t+1|t), so we will condition
this equation on Y(t):

x(t+1)|Y(t) = A*x(t)|Y(t) + w(t) //process noise is independent of measurements

Taking the expected value of both sides, we see that:

x_hat(t+1|t) = A*x_hat(t|t)

For S(t+1|t), we can go back to the definition and work some algebra with relative ease:

S(t+1|t) = E((x(t+1) - x_hat(t+1|t))*(x(t+1) - x_hat(t+1|t))')
...
//sub in x(t+1) = A*x(t)+w(t), above expression for x_hat(t+1|t)

S(t+1|t) = A*S(t|t)*A' + W

Thus the prediction for the next/updated state is the following "time update":

----------------------------
x_hat(t+1|t) = A*x_hat(t|t)

S(t+1|t) = A*S(t|t)*A' + W
----------------------------

===============================
=== Putting it all together ===
===============================

The Kalman filter gives us a forward recursion in time where we successively repeat the
"measurement update" and the "time update" to get an optimal estimation of our state. 

To start, we need initial conditions: 

x_hat(0|-1) = mean(x(0)), S(0|-1) = E((x(0) - mean(x(0)))*(x(0) - mean(x(0)))') == S(0)

And the measurement and time updates are repeated below for convenience: 

--------------------------
--- Measurement Update ---
--------------------------------------------------------------------------------------
x_hat(t|t) = x_hat(t|t-1) + S(t|t-1)*C'*(C*S(t|t-1)*C'+V).inv*(y(t) - C*x_hat(t|t-1))

S(t|t) = S(t|t-1) - S(t|t-1)*C'*(C*S(t|t-1)*C'+V).inv*C*S(t|t-1)
--------------------------------------------------------------------------------------

-------------------
--- Time Update ---
----------------------------
x_hat(t+1|t) = A*x_hat(t|t)

S(t+1|t) = A*S(t|t)*A' + W
----------------------------

==============================
=== Software Documentation ===
==============================

See example in KalmanTestScript. Assuming the user can properly set up problem definition data,
the user can call a simple test routine to simulate the Kalman Filter:

[x_kalman, y_error] = KalmanTestRoutine(S0, x0bar, W, wbar, V, vbar, A, C, y_data, numTimeSteps);

For real-time Kalman Filtering, copy out the code in the inner-loop of the function KalmanTestRoutine,
and make it part of your application's inner loop, updating with new sensor values. It might look
something like the following (in part MATLAB, part pseudocode):

% Simulation. For a real-time system, this loop runs continually.
while (y_data = new_sensor_data())

   % Apply measurement and time updates: 
   [x_hat_measured, S_measured] = KalmanMeasurementUpdate(x_hat_previous, S_previous, C, V, y_data, vbar);
   [x_hat_updated, S_updated] = KalmanTimeUpdate(x_hat_measured, S_measured, A, W, wbar);

   % Recrod the Kalman filtered state estimate, and the measurement error: 
   % (in application code, this is where we look at quantities of interest)
   % x_kalman(:,i) = x_hat_updated; %or take a look at x_hat_updated
   % y_error(:,i) = y_data - C*x_hat_measured - vbar; 
   % Here it may be wise to not do history tracking, as the vectors can become quite large.

   % Update recursively for next iteration:
   S_previous = S_updated;
   x_hat_previous = x_hat_updated;

   do_stuff_with_optimal_state_estimate(x_hat_updated);    

end

=========================
=== Application Notes ===
=========================

This section contains notes pertaining to the effective use of the Kalman filter and will be
updated as more insights are gained from use of the software/algorithm. 

The first note is a heuristic regarding how to set up the process and measurement noise initial
covariances, i.e. W and V respectively. 

As the "ratio" of V/W increases ("ratio" because the dimensions need not be the same; we may look at 
relative matrix norms for example), it means that we trust new measurements *less* than we would vs.
our previous state value. As V/W decreases, it implies that we trust measurements *more* relative to
our previous estimates. 

We can create a proportionality argument for this, where we look at the effects of quantities going up
or down in value to make simplifications, and take a look at the results. We will also consider short
time steps, which imply an approximately steady-state.

To start, consider the measurement update formula:

x_hat(t|t) = x_hat(t|t-1) + S(t|t-1)*C'*(C*S(t|t-1)*C'+V).inv*(y(t) - C*x_hat(t|t-1))

Using the recursive formulae for S(t|t), S(t+1|t), we can substitute the former into the latter to obtain
the following Ricatti recursion:

S(t+1|t) = A*S(t|t-1)*A' + W - A*S(t|t-1)*C'*(C*S(t|t-1)*C' + V).inv*C*S(t|t-1)*A'

From these two formulas, we can see the relative effects of V and W on the measurement discrepancy term,
y(t) - C*x_hat(t|t-1). We will consider a purely scalar case for the intuitive argument. 

The coefficient to the measurement discrepancy, also called the "Kalman Gain", is proportional to:

S(t|t-1)*1/(S(t|t-1) + V) = S(t|t-1)/(S(t|t-1) + V)

And from the second formula, we see that for close to steady state (which would be an equivalent condition for
very small changes between t and t+1):

S ~ S + W - S*(1/(S+V))*S //steady-state: S(t+1|t) ~ S(t|t-1) ~ S

Or, S+V ~ S^2 / W

We can approximately solve this quadratic formula for S, to obtain that
S ~ W +/- sqrt(W^2 + 4*V)

Substituting in above, the Kalman Gain K is proportional to:

K ~ S/(S+V) 
  ~ W/S
  ~ W / (W +/- sqrt(W^2 + 4*V))
  ~ 1 / (1 + sqrt(1 + 4*V/W^2)) 

So that |K| ~ W/sqrt(V)

Which intuitively confirms that as W increases relative to V, we trust measurements more, and vise-versa.
(K negative: large |K| still implies we're making corrections to our state based on the measurement discrepancy.)

This may show our argument to make some sense in a very limited way. Changes in problem parameters A,C for instance
may completely skew this proportionality; not being scalar may mean that different proportionalities of measurement/state
trust apply to different components of the state. 

What is the take away? 

While there is no "right answer" for how to set this ratio, roughly it defines a trade-off, or regularization, 
between signal smoothness and signal error; the latter is decreased by trusting measurements, and thus course-
corrects more towards them. 

The take-away is to understand the relative impact of W and V and use trial-and-error on sample data to obtain a
trade-off appropriate to your application. 

====================================================
=== Further Adaptations for Nonlinear Estimation ===
====================================================

The Kalman Filter lends itself to adaptations that can be used to approximate nonlinear optimal estimation. This
section will discuss two methods, and roughly describe how they could be implemented in code. 

Extended Kalman Filter:
-----------------------

For a non-linear markov model, we have:

x(t+1) = f(x(t)) + w(t)
y(t) = g(x(t)) + v(t)

Where f is the dynamics functions and need not be linear, and g is the measurement function which also need not be
linear. The Extended Kalman Filter (EKF) replaces f and g with affine approximations at the current estimate, and
then uses the standard KF formulas for measurement and time updates. This is akin to propagating an approximation
of the conditional expectation and covariance of quantities. I.e. x(t|Y(t)) is approximate now, so that
E(x(t) - x_hat(t|t)) is approximately equal to 0. 

To linearize at the current estimate, we replace A and C with the appropriate Jacobian matrices evaluated at the 
current estimate and previous estimate. The other minor change is changing the measurement discrepancy term to use 
g(x(t)). To that end we have:

-----------------
--- Jacobians ---
----------------------------------------------------------------------------------------------------------------
A = df/dx(x_hat(t|t) //Jacobian of f(x) evaluated at point x_hat(t|t)
C = dg/dx(x_hat(t|t-1) //for more on Jacobians, see http://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant 
----------------------------------------------------------------------------------------------------------------

--------------------------
--- Measurement Update ---
--------------------------------------------------------------------------------------
x_hat(t|t) = x_hat(t|t-1) + S(t|t-1)*C'*(C*S(t|t-1)*C'+V).inv*(y(t) - g(x_hat(t|t-1)))

S(t|t) = S(t|t-1) - S(t|t-1)*C'*(C*S(t|t-1)*C'+V).inv*C*S(t|t-1)
--------------------------------------------------------------------------------------

-------------------
--- Time Update ---
----------------------------
x_hat(t+1|t) = A*x_hat(t|t)

S(t+1|t) = A*S(t|t)*A' + W
---------------------------- 

The derivation comes from the multivariate Taylor expansion of the above equations, followed by taking the 
appropriate expectations. See http://stanford.edu/class/ee363/lectures/kf.pdf slides 5 and 6. This particular
derivation considers f(x(t), w(t)) and g(x(t), v(t)), i.e. the noise is considered to distort nonlinearly. This
results in very slight modifications to what is presented above, in fact there is only one major difference: for 
the S(t+1|t) equation, replace W with B*Sw*B', where Sw (= W) is the covariance of w(t). Other than that, evaluate 
functions and Jacobians in the formulas with the noise arguments set to zero.

(Additional sources for EKF formulas:
http://en.wikipedia.org/wiki/Extended_Kalman_filter#Discrete-time_predict_and_update_equations
http://en.wikipedia.org/wiki/Kalman_filter#Predict ) 

Example software might look like the following, which is a mix of MATLAB and pseudocode:   

% Simulation. For a real-time system, this loop runs continually.
while (y_data = new_sensor_data())

   % Obtain Jacobian C:
   C = get_Jacobian_g(x_hat_previous); % must create a function to return the matrix corresponding to Jacobian dg/dx

   % Apply measurement update: 
   [x_hat_measured, S_measured] = KalmanMeasurementUpdate(x_hat_previous, S_previous, C, V, y_data, vbar);

   % Obtain Jacobian A:
   A = get_Jacobian_f(x_hat_measured); % again, custom-coded function particular to your application

   % Apply time update:
   [x_hat_updated, S_updated] = KalmanTimeUpdate(x_hat_measured, S_measured, A, W, wbar);

   % Update recursively for next iteration:
   S_previous = S_updated;
   x_hat_previous = x_hat_updated;

   do_stuff_with_optimal_state_estimate(x_hat_updated);    

end

Monte Carlo Methods / Particle Filter
-------------------------------------

Another way to handle nonlinearity is to consider the sampling of estimated and noise quantities, where we assume
that samples come from the respective normal distributions. I.e. x(t) ~ N(x_hat(t|t), S(t|t)). To do this, the
algorithm must have a method of generating samples from normal distributions, including generating samples of the
noise w(t) and v(t). Practically, this latter requirement means that we need noise models of w(t) and v(t) a priori.

We will break this process down into measurement and time updates:

1. Monte Carlo Measurement Update
1.1 Generate K samples of x(t) (call them x(t,k), k = 1,...,K) from N(x_hat(t|t-1), S(t|t-1))
1.2 Generate K samples of v(t) (call them v(t,k), similarly)
1.3 These give samples y(t,k) = g(x(t,k)) + v(t,k)
1.4 Use sample mean as estimate of E(y(t)) = (1/K)*sum(y(t,k)), summing from k = 1,...,K
1.5 Use sample mean to estimate covariances:
    Sxy = (1/K)*sum((x(t,k)-x_hat(t,k))*(y(t,k)-E(y(t)))'), sum from 1,...,K
    Syy = (1/K)*sum((y(t,k)-E(y(t)))*(y(t,k)-E(y(t)))'), sum from 1,...,K
1.6 The approximations for x_hat(t|t) and S(t|t) come from the standard formula for the conditional of jointly Gaussian
    vars that have an affine relationship (see: MMSE, Linear Measurement Model, preceding sections):
    x_hat(t|t) = x_hat(t|t-1) + Sxy*Syy.inv*(y(t) - E(y(t))) //where y(t) is the actual new measurement
    S(t|t) = S(t|t-1) - Sxy*Syy.inv*Sxy'
    
2. Monte Carlo Time Update
2.1 Generate K samples of x(t) (call them x(t,k), k = 1,...,K) from N(x_hat(t|t), S(t|t))
2.2 Generate K samples of w(t) (call them w(t,k) similarly)
2.3 These samples give x(t+1,k) = f(x(t,k)) + w(t,k), and x(t+1,k) are samples of x(t+1|t)
2.4 Use the sample mean of the above for x_hat(t+1|t) = (1/K)*sum(x(t+1,k)), sum from k = 1,...,K
2.5 Use the sample covariance to calculate S(t+1|t) = (1/K)*sum((x(t+1,k)-x_hat(t+1|t))*(x(t+1,k)-x_hat(t+1|t))'),
    summing from k = 1,...,K

=================================
=== Adding Inputs for Control ===
=================================

The Kalman Filter can be thought of as a way to filter out the noise from a control system. Adding a control signal,
thus forming the system:

x(t+1) = A*x(t) + B*u(t)
y(t) = C*x(t) 

does not fundamentally change this. We can view the two problems of filtering and control to be separate. In practical
terms, one can use a routine such as "state = KalmanFilter(state)", and then apply whatever control law they wish to
"state". At every time step, this means: get new measurement, run measurement update, run time update with control. 

More concretely, one can add in control with Kalman Filtering by modifying the time update:  

x_hat(t+1|t) = A*x_hat(t|t) + B*u(t) 

For more info, the following reference derives how to combine Kalman Filtering with a common control scheme, the 
Linear Quadratic Regulator (i.e. state feedback):
